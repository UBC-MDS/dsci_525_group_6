{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-training",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "from memory_profiler import memory_usage \n",
    "\n",
    "# Jupyter Lab cell extensions\n",
    "%load_ext rpy2.ipython \n",
    "%load_ext memory_profiler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-probe",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fewer-berlin",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Create data directories if they don't exist\n",
    "output_raw_dir = \"../data/raw\"\n",
    "output_proc_dir = \"../data/processed\"\n",
    "os.makedirs(output_raw_dir, exist_ok=True)\n",
    "os.makedirs(output_proc_dir, exist_ok=True)\n",
    "\n",
    "# Retrieve the file id for the rainfall data and download as a zip\n",
    "file_id = 26766812\n",
    "response = requests.get(f'https://api.figshare.com/v2/file/download/{file_id}')\n",
    "fh = open(output_raw_dir + '/data.zip', 'wb')\n",
    "fh.write(response.content)\n",
    "fh.close()\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(output_raw_dir + '/data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_raw_dir + '/data_extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-antarctica",
   "metadata": {},
   "source": [
    "### Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "known-allergy",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1007.22 MiB, increment: 0.21 MiB\n",
      "../data/processed/combined_data.csv file saved!\n",
      "CPU times: user 7min 55s, sys: 22.9 s, total: 8min 18s\n",
      "Wall time: 8min 34s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "2  1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "3  1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "4  1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)            model  \n",
       "0   4.244226e-13  MPI-ESM-1-2-HAM  \n",
       "1   4.217326e-13  MPI-ESM-1-2-HAM  \n",
       "2   4.498125e-13  MPI-ESM-1-2-HAM  \n",
       "3   4.251282e-13  MPI-ESM-1-2-HAM  \n",
       "4   4.270161e-13  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "output_combined_filepath = output_proc_dir + \"/combined_data.csv\"\n",
    "\n",
    "# Gather extracted .csv files and add a model identification column\n",
    "csvfiles = [file for file in os.listdir(output_raw_dir + \"/data_extracted\") if \".csv\" in file]\n",
    "frame_list = []\n",
    "for csvfile in csvfiles:\n",
    "    df = pd.read_csv(output_raw_dir + \"/data_extracted/\" + csvfile, index_col=None, header=0)\n",
    "    df['model'] = csvfile.split(\"_\")[0] \n",
    "    frame_list.append(df)\n",
    "\n",
    "# Combine as a single dataframe\n",
    "combined_df = pd.concat(frame_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Save combined data frame to disk\n",
    "combined_df.to_csv(output_combined_filepath)\n",
    "print(output_combined_filepath + \" file saved!\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-check",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Run time and memory Usage Discussion:\n",
    "\n",
    "peak memory: 1061.02 MiB, increment: 0.00 MiB\n",
    "Wall time: 1min 51s\n",
    "\n",
    "peak memory: 924.72 MiB, increment: 0.08 MiB\n",
    "CPU times: user 48 s, sys: 5.18 s, total: 53.2 s\n",
    "Wall time: 55.6 s\n",
    "\n",
    "peak memory: 935.61 MiB, increment: 0.11 MiB\n",
    "CPU times: user 56.5 s, sys: 3.65 s, total: 1min\n",
    "Wall time: 1min\n",
    "\n",
    "peak memory: 1018.20 MiB, increment: 0.19 MiB\n",
    "CPU times: user 1min 2s, sys: 12 s, total: 1min 14s\n",
    "Wall time: 1min 20s\n",
    "\n",
    "#### Discussion:\n",
    "\n",
    "Running the combining data process is very RAM intensive. It's important to verify we have enough RAM and hard disk space available before runnning the notebook. Otherwise, the jupyter notebook will crash. We ran the cell above, and our computers took around 1min to run and the peak memory usage was around 1000 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-purse",
   "metadata": {},
   "source": [
    "### Load the combined CSV to memory and perform a simple EDA\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "* Changing dtype of your data\n",
    "* Load just columns what we want\n",
    "* Loading in chunks\n",
    "* Dask\n",
    "\n",
    "2. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-reaction",
   "metadata": {},
   "source": [
    "#### Loading in chunks for counting the model column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thermal-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "observed              46020\n",
      "dtype: int64\n",
      "peak memory: 8162.10 MiB, increment: 0.06 MiB\n",
      "CPU times: user 1min 16s, sys: 10.2 s, total: 1min 26s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "import dask.dataframe as dd\n",
    "\n",
    "model_counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(output_combined_filepath, chunksize=10_000_000):\n",
    "    model_counts = model_counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(model_counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-sharing",
   "metadata": {},
   "source": [
    "#### Loading only the column we want for the EDA, which is the model column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unauthorized-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-ESM2           3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "observed              46020\n",
      "Name: model, dtype: int64\n",
      "peak memory: 2870.74 MiB, increment: 589.55 MiB\n",
      "CPU times: user 35.3 s, sys: 3.31 s, total: 38.6 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "data_model = pd.read_csv(output_combined_filepath, usecols=[\"model\"])\n",
    "print(data_model[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-poster",
   "metadata": {},
   "source": [
    "#### Loading using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deadly-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "observed              46020\n",
      "Name: model, dtype: int64\n",
      "peak memory: 3520.40 MiB, increment: 1015.82 MiB\n",
      "CPU times: user 1min 40s, sys: 22 s, total: 2min 2s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "ddf = dd.read_csv(output_combined_filepath)\n",
    "print(ddf[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-viking",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "In this section, we experimented with loading using chunk size of 10,000,000, loading using only the column we wanted, and loading using Dask.  \n",
    "\n",
    "Comparing the results:\n",
    "* Loading using chunk size of 10,000,000:  \n",
    "peak memory: 3078.15 MiB, increment: 2934.44 MiB\n",
    "Wall time: 1min 59s\n",
    "\n",
    "* Loading using only the column we wanted:  \n",
    "peak memory: 1424.96 MiB, increment: 953.43 MiB\n",
    "Wall time: 1min 1s\n",
    "\n",
    "* Loading using Dask:  \n",
    "peak memory: 1943.04 MiB, increment: 995.03 MiB\n",
    "Wall time: 1min 2s\n",
    "\n",
    "From the above runtime stats, we can observe that loading using chunk size takes the most of the memory and longer wall time comparing to loading using only the column we wanted and loading using Dask. Loading using only the column we wanted has the minimal number of peak memory usage and wall time comparing to loading using Dask.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-recommendation",
   "metadata": {},
   "source": [
    "### Perform a simple EDA in R\n",
    "\n",
    "Pick an approach to transfer the dataframe from python to R.\n",
    "* Parquet file\n",
    "* Feather file (We chose this one)\n",
    "* Pandas exchange\n",
    "* Arrow exchange\n",
    "\n",
    "### Discuss why you chose this approach over others.\n",
    "\n",
    "From the lecture notes, feather is faster than the parquet or arrow format in writing to files and it's convenient to use. It's very common to use feather with the R programming language because the API for reading and writing is simple to understand and close to the base R file reading and writing syntax. We also referred to [this article](https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d) before choosing this format, which performed a variety of benchmark comparison. From the experimentations of different file formats, the comparisons show that feather format is an ideal choice to store the data between Jupyter notebook sessions. Using feather format will result in high I/O speed and it doesn’t take huge memory on the computer disk; it also doesn’t need any unpacking when loaded the data back into RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loaded-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arrow, parquet, and feather packages\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import rpy2.rinterface\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monthly-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#just seeing if its available\n",
    "library(\"arrow\")\n",
    "library(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "christian-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3227.55 MiB, increment: 1248.86 MiB\n",
      "CPU times: user 26.6 s, sys: 14.6 s, total: 41.3 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dataset = ds.dataset(output_combined_filepath, format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finite-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.72 s, sys: 17.1 s, total: 24.8 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# experiment in writing in feather format \n",
    "output_feather_filepath = output_proc_dir + '/combined_data.feather'\n",
    "feather.write_feather(table, output_feather_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "growing-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "Time difference of 8.194424 secs\n",
      "\u001b[90m# A tibble: 28 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 18 more rows\u001b[39m\n",
      "CPU times: user 5.88 s, sys: 2.77 s, total: 8.65 s\n",
      "Wall time: 8.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "# Load R imports\n",
    "library(arrow)\n",
    "library(dplyr)\n",
    "\n",
    "### here we are showing how much time it took to read a feather file what we wrote in python\n",
    "start_time <- Sys.time()\n",
    "\n",
    "output_feather_filepath = '../data/processed/combined_data.feather'\n",
    "r_table <- arrow::read_feather(output_feather_filepath, col_select=c(\"model\"))\n",
    "print(class(r_table))\n",
    "\n",
    "result <- count(r_table, model)\n",
    "\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-submission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
